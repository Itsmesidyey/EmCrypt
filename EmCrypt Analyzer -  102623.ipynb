{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3c207279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#SpellCorrection\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "import string\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "36401f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812771</td>\n",
       "      <td>Mon Apr 06 22:20:19 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>robrobbierobert</td>\n",
       "      <td>@octolinz16 It it counts, idk why I did either...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822994</td>\n",
       "      <td>Mon Apr 06 22:22:56 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sorano916</td>\n",
       "      <td>Didn't place in the Peeps contest but thanks f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812723</td>\n",
       "      <td>Mon Apr 06 22:20:19 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TLeC</td>\n",
       "      <td>@caregiving I couldn't bear to watch it.  And ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1467813992</td>\n",
       "      <td>Mon Apr 06 22:20:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>swinspeedx</td>\n",
       "      <td>one of my friend called me, and asked to meet ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target         ids                          date      flag  \\\n",
       "13       0  1467812771  Mon Apr 06 22:20:19 PDT 2009  NO_QUERY   \n",
       "3        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "45       4  1467822994  Mon Apr 06 22:22:56 PDT 2009  NO_QUERY   \n",
       "12       0  1467812723  Mon Apr 06 22:20:19 PDT 2009  NO_QUERY   \n",
       "21       0  1467813992  Mon Apr 06 22:20:38 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                               text  \n",
       "13  robrobbierobert  @octolinz16 It it counts, idk why I did either...  \n",
       "3           ElleCTF    my whole body feels itchy and like its on fire   \n",
       "45        sorano916  Didn't place in the Peeps contest but thanks f...  \n",
       "12             TLeC  @caregiving I couldn't bear to watch it.  And ...  \n",
       "21       swinspeedx  one of my friend called me, and asked to meet ...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "DATASET_COLUMNS=['target','ids','date','flag','user','text']\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "df = pd.read_csv('Smalldata.csv', encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3d8aeada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3bb990a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'ids', 'date', 'flag', 'user', 'text'], dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "999d922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data is 50\n"
     ]
    }
   ],
   "source": [
    "print('length of data is', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "59bc4e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5a54bdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of     target         ids                          date      flag  \\\n",
       "0        0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1        0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2        0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4        0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "5        0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "6        0  1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "7        0  1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "8        0  1467811795  Mon Apr 06 22:20:05 PDT 2009  NO_QUERY   \n",
       "9        0  1467812025  Mon Apr 06 22:20:09 PDT 2009  NO_QUERY   \n",
       "10       0  1467812416  Mon Apr 06 22:20:16 PDT 2009  NO_QUERY   \n",
       "11       0  1467812579  Mon Apr 06 22:20:17 PDT 2009  NO_QUERY   \n",
       "12       0  1467812723  Mon Apr 06 22:20:19 PDT 2009  NO_QUERY   \n",
       "13       0  1467812771  Mon Apr 06 22:20:19 PDT 2009  NO_QUERY   \n",
       "14       0  1467812784  Mon Apr 06 22:20:20 PDT 2009  NO_QUERY   \n",
       "15       0  1467812799  Mon Apr 06 22:20:20 PDT 2009  NO_QUERY   \n",
       "16       0  1467812964  Mon Apr 06 22:20:22 PDT 2009  NO_QUERY   \n",
       "17       0  1467813137  Mon Apr 06 22:20:25 PDT 2009  NO_QUERY   \n",
       "18       0  1467813579  Mon Apr 06 22:20:31 PDT 2009  NO_QUERY   \n",
       "19       0  1467813782  Mon Apr 06 22:20:34 PDT 2009  NO_QUERY   \n",
       "20       0  1467813985  Mon Apr 06 22:20:37 PDT 2009  NO_QUERY   \n",
       "21       0  1467813992  Mon Apr 06 22:20:38 PDT 2009  NO_QUERY   \n",
       "22       0  1467814119  Mon Apr 06 22:20:40 PDT 2009  NO_QUERY   \n",
       "23       0  1467814180  Mon Apr 06 22:20:40 PDT 2009  NO_QUERY   \n",
       "24       0  1467814192  Mon Apr 06 22:20:41 PDT 2009  NO_QUERY   \n",
       "25       4  1467822272  Mon Apr 06 22:22:45 PDT 2009  NO_QUERY   \n",
       "26       4  1467822273  Mon Apr 06 22:22:45 PDT 2009  NO_QUERY   \n",
       "27       4  1467822283  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "28       4  1467822287  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "29       4  1467822293  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "30       4  1467822391  Mon Apr 06 22:22:47 PDT 2009  NO_QUERY   \n",
       "31       4  1467822447  Mon Apr 06 22:22:51 PDT 2009  NO_QUERY   \n",
       "32       4  1467822465  Mon Apr 06 22:22:48 PDT 2009  NO_QUERY   \n",
       "33       4  1467822489  Mon Apr 06 22:22:49 PDT 2009  NO_QUERY   \n",
       "34       4  1467822496  Mon Apr 06 22:22:49 PDT 2009  NO_QUERY   \n",
       "35       4  1467822530  Mon Apr 06 22:22:49 PDT 2009  NO_QUERY   \n",
       "36       4  1467822531  Mon Apr 06 22:22:49 PDT 2009  NO_QUERY   \n",
       "37       4  1467822635  Mon Apr 06 22:22:51 PDT 2009  NO_QUERY   \n",
       "38       4  1467822729  Mon Apr 06 22:22:52 PDT 2009  NO_QUERY   \n",
       "39       4  1467822796  Mon Apr 06 22:22:53 PDT 2009  NO_QUERY   \n",
       "40       4  1467822814  Mon Apr 06 22:22:54 PDT 2009  NO_QUERY   \n",
       "41       4  1467822899  Mon Apr 06 22:22:58 PDT 2009  NO_QUERY   \n",
       "42       4  1467822924  Mon Apr 06 22:22:55 PDT 2009  NO_QUERY   \n",
       "43       4  1467822936  Mon Apr 06 22:22:57 PDT 2009  NO_QUERY   \n",
       "44       4  1467822964  Mon Apr 06 22:22:56 PDT 2009  NO_QUERY   \n",
       "45       4  1467822994  Mon Apr 06 22:22:56 PDT 2009  NO_QUERY   \n",
       "46       4  1467823016  Mon Apr 06 22:22:57 PDT 2009  NO_QUERY   \n",
       "47       4  1467823046  Mon Apr 06 22:22:57 PDT 2009  NO_QUERY   \n",
       "48       4  1467823079  Mon Apr 06 22:22:58 PDT 2009  NO_QUERY   \n",
       "49       4  1467823109  Mon Apr 06 22:22:58 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                               text  \n",
       "0   _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1     scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2          mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3           ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4            Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "5          joy_wolf                      @Kwesidei not the whole crew   \n",
       "6           mybirch                                        Need a hug   \n",
       "7              coZZ  @LOLTrish hey  long time no see! Yes.. Rains a...  \n",
       "8   2Hood4Hollywood               @Tatiana_K nope they didn't have it   \n",
       "9           mimismo                          @twittera que me muera ?   \n",
       "10   erinx3leannexo        spring break in plain city... it's snowing   \n",
       "11     pardonlauren                         I just re-pierced my ears   \n",
       "12             TLeC  @caregiving I couldn't bear to watch it.  And ...  \n",
       "13  robrobbierobert  @octolinz16 It it counts, idk why I did either...  \n",
       "14      bayofwolves  @smarrison i would've been the first, but i di...  \n",
       "15       HairByJess  @iamjazzyfizzle I wish I got to watch it with ...  \n",
       "16   lovesongwriter  Hollis' death scene will hurt me severely to w...  \n",
       "17         armotley                               about to file taxes   \n",
       "18       starkissed  @LettyA ahh ive always wanted to see rent  lov...  \n",
       "19        gi_gi_bee  @FakerPattyPattz Oh dear. Were you drinking ou...  \n",
       "20           quanvu  @alydesigns i was out most of the day so didn'...  \n",
       "21       swinspeedx  one of my friend called me, and asked to meet ...  \n",
       "22        cooliodoc   @angry_barista I baked you a cake but I ated it   \n",
       "23       viJILLante             this week is not going as i had hoped   \n",
       "24       Ljelli3166                         blagh class at 8 tomorrow   \n",
       "25            ersle    I !!!LOVE @Health4UandPets u guys r the best!!√ä  \n",
       "26         becca210  im!!!!!? meeting up with one of my besties ton...  \n",
       "27        Wingman29  @DaRealSunisaKim Thanks for the Twitter add, S...  \n",
       "28        katarinka  Being sick can be really cheap when it hurts t...  \n",
       "29      _EmilyYoung    @LovesBrooklyn2 he has that effect on everyone√ä  \n",
       "30    ajarofalmonds  @ProductOfFear You can tell him that I just bu...  \n",
       "31        vmdavinci  @r_keith_hill Thans for your response. Ihad al...  \n",
       "32    jessicavaliyi  @KeepinUpWKris I am so jealous, hope you had a...  \n",
       "33       emmasaur28  @tommcfly ah, congrats mr fletcher for finally...  \n",
       "34    SherylBreuker  @e4VoIP I RESPONDED√ä Stupid cat is helping me ...  \n",
       "35          claaare  crazy day of school. there for 10 hours straii...  \n",
       "36   Hollywood_Trey  @naughtyhaughty HOW DID I FORGET ABOUT TWO AND...  \n",
       "37       JJLuver756  @nileyjileyluver Haha, don't worry! You'll get...  \n",
       "38        tophatdog  @soundwav2010 At least I won't be the only one...  \n",
       "39  toothfairycyber  @LutheranLucciol Make sure you DM me if you po...  \n",
       "40    misstoriblack               Just added tweetie to my new iPhone√ä  \n",
       "41        estariray  @michellardi i really don't know. i think its ...  \n",
       "42           ddjuli         @nicolerichie: your picture is very sweet√ä  \n",
       "43      adamjackson  Catching Up on Emails, RSS and Random BACN. Th...  \n",
       "44      lightleaves  Dancing around the room in Pjs, jamming to my ...  \n",
       "45        sorano916  Didn't place in the Peeps contest but thanks f...  \n",
       "46   livelaughenjoy  Going to bed so goodnight everyone√ä and sweet ...  \n",
       "47           rwang0  @LittleLumen walking over to put the deposit d...  \n",
       "48  oOLuciousLisaOo  is now followinq @DAChesterFrench , you shud d...  \n",
       "49         mark_liu  @LordPov Are you meant to add on the back of t...  >"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "35dbc907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target     int64\n",
       "ids        int64\n",
       "date      object\n",
       "flag      object\n",
       "user      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "28aa335c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "12f3bc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of columns in the data is:   6\n",
      "Count of rows in the data is:   50\n"
     ]
    }
   ],
   "source": [
    "print('Count of columns in the data is:  ', len(df.columns))\n",
    "print('Count of rows in the data is:  ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "732323c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0941299b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8e7e1c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "data=df[['text','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "332e7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['target'] == 4, 'target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6d382d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6189537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data[data['target'] == 1]\n",
    "data_neg = data[data['target'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0fcbf346",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data_pos.iloc[:int(25)]\n",
    "data_neg = data_neg.iloc[:int(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6e426bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([data_pos, data_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3ed5288c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    @alydesigns i was out most of the day so didn'...\n",
       "21    one of my friend called me, and asked to meet ...\n",
       "22     @angry_barista I baked you a cake but I ated it \n",
       "23               this week is not going as i had hoped \n",
       "24                            blagh class at  tomorrow \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "dataset['text'] = dataset['text'].apply(lambda x: cleaning_numbers(x))\n",
    "dataset['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2180cf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25                             I LOVE u guys r the best\n",
      "26    im meeting up with one of my besties tonight C...\n",
      "27    Thanks for the Twitter add Sunisa I got to mee...\n",
      "28    Being sick can be really cheap when it hurts t...\n",
      "29                       he has that effect on everyone\n",
      "30    You can tell him that I just burst out laughin...\n",
      "31    Thans for your response Ihad already find this...\n",
      "32    I am so jealous hope you had a great time in v...\n",
      "33    ah congrats mr fletcher for finally joining tw...\n",
      "34    I RESPONDED Stupid cat is helping me type Forg...\n",
      "35    crazy day of school there for hours straiiight...\n",
      "36    HOW DID I FORGET ABOUT TWO AND A HALF MEN I LO...\n",
      "37           Haha don t worry You ll get the hang of it\n",
      "38    At least I won t be the only one feeling lost ...\n",
      "39    Make sure you DM me if you post a link to that...\n",
      "40                  Just added tweetie to my new iPhone\n",
      "41    i really don t know i think its Globe yeah san...\n",
      "42                           your picture is very sweet\n",
      "43    Catching Up on Emails RSS and Random BACN Then...\n",
      "44    Dancing around the room in Pjs jamming to my i...\n",
      "45    Didn t place in the Peeps contest but thanks f...\n",
      "46    Going to bed so goodnight everyone and sweet d...\n",
      "47        walking over to put the deposit down tomorrow\n",
      "48                is now followinq you shud do tha same\n",
      "49    Are you meant to add on the back of that quot ...\n",
      "0     Awww that s a bummer You shoulda got David Car...\n",
      "1     is upset that he can t update his Facebook by ...\n",
      "2     I dived many times for the ball Managed to sav...\n",
      "3        my whole body feels itchy and like its on fire\n",
      "4     no it s not behaving at all i m mad why am i h...\n",
      "5                                    not the whole crew\n",
      "6                                            Need a hug\n",
      "7     hey long time no see Yes Rains a bit only a bi...\n",
      "8                              nope they didn t have it\n",
      "9                                          que me muera\n",
      "10              spring break in plain city it s snowing\n",
      "11                            I just re pierced my ears\n",
      "12    I couldn t bear to watch it And I thought the ...\n",
      "13    It it counts idk why I did either you never ta...\n",
      "14    i would ve been the first but i didn t have a ...\n",
      "15    I wish I got to watch it with you I miss you a...\n",
      "16    Hollis death scene will hurt me severely to wa...\n",
      "17                                  about to file taxes\n",
      "18    ahh ive always wanted to see rent love the sou...\n",
      "19    Oh dear Were you drinking out of the forgotten...\n",
      "20    i was out most of the day so didn t get much done\n",
      "21    one of my friend called me and asked to meet w...\n",
      "22                     I baked you a cake but I ated it\n",
      "23                this week is not going as i had hoped\n",
      "24                              blagh class at tomorrow\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def clean_tweet(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Remove hashtags and mentions\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "\n",
    "    # Remove any remaining special characters and whitespace\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', ' ', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'text' column in your dataset\n",
    "dataset['text'] = dataset['text'].apply(clean_tweet)\n",
    "\n",
    "# Assuming you have a dataset and you've applied the clean_tweet function as you mentioned\n",
    "\n",
    "# you can view the 'text' column in the entire dataset\n",
    "print(dataset['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8a2a1fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    i was out most of the day so didn t get much done\n",
       "21    one of my friend called me and asked to meet w...\n",
       "22                     I baked you a cake but I ated it\n",
       "23                this week is not going as i had hoped\n",
       "24                              blagh class at tomorrow\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "dataset['text'] = dataset['text'].apply(lambda x: cleaning_repeating_char(x))\n",
    "row_index = 0\n",
    "dataset['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7fd42b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  target\n",
      "25                           I LOVE u guys i the best       1\n",
      "26  im meeting up with one of my besties tonight C...       1\n",
      "27  Thanks for the Twitter add punish I got to mee...       1\n",
      "28  Being sick can be really cheap when it hurts t...       1\n",
      "29                     he has that effect on everyone       1\n",
      "30  You can tell him that I just burst out laughin...       1\n",
      "31  than for your response had already find this a...       1\n",
      "32  I am so jealous hope you had a great time in v...       1\n",
      "33  ah congrats my fletcher for finally joining tw...       1\n",
      "34  I RESPONDED Stupid cat is helping me type Forg...       1\n",
      "35  crazy day of school there for hours straight a...       1\n",
      "36  HOW DID I FORGET ABOUT TWO AND A HALF MEN I LO...       1\n",
      "37        Haha don i worry You all get the hang of it       1\n",
      "38  At least I won i be the only one feeling lost ...       1\n",
      "39  Make sure you do me if you post a link to that...       1\n",
      "40                Just added sweetie to my new iPhone       1\n",
      "41  i really don i know i think its Globe yeah san...       1\n",
      "42                         your picture is very sweet       1\n",
      "43  Catching Up on Emails ass and Random back Then...       1\n",
      "44  Dancing around the room in pas jamming to my i...       1\n",
      "45  Didn i place in the Peeps contest but thanks f...       1\n",
      "46  Going to bed so goodnight everyone and sweet d...       1\n",
      "47      walking over to put the deposit down tomorrow       1\n",
      "48              is now following you shut do tha same       1\n",
      "49  Are you meant to add on the back of that quit ...       1\n",
      "0   aww that i a bummer You shoulda got David Carr...       0\n",
      "1   is upset that he can i update his Facebook by ...       0\n",
      "2   I dived many times for the ball Managed to sav...       0\n",
      "3      my whole body feels itchy and like its on fire       0\n",
      "4   no it i not behaving at all i i mad why am i h...       0\n",
      "5                                  not the whole crew       0\n",
      "6                                          Need a hug       0\n",
      "7   hey long time no see Yes Rains a bit only a bi...       0\n",
      "8                            nope they didn i have it       0\n",
      "9                                        que me meera       0\n",
      "10            spring break in plain city it i snowing       0\n",
      "11                          I just re pierced my ears       0\n",
      "12  I couldn i bear to watch it And I thought the ...       0\n",
      "13  It it counts ink why I did either you never ta...       0\n",
      "14  i would ve been the first but i didn i have a ...       0\n",
      "15  I wish I got to watch it with you I miss you a...       0\n",
      "16  Hollis death scene will hurt me severely to wa...       0\n",
      "17                                about to file taxes       0\n",
      "18  ah ive always wanted to see rent love the soun...       0\n",
      "19  Oh dear Were you drinking out of the forgotten...       0\n",
      "20  i was out most of the day so didn i get much done       0\n",
      "21  one of my friend called me and asked to meet w...       0\n",
      "22                    I baked you a cake but I ate it       0\n",
      "23              this week is not going as i had hoped       0\n",
      "24                             blah class at tomorrow       0\n"
     ]
    }
   ],
   "source": [
    "# Function for spell correction using pySpellChecker\n",
    "def spell_correction(text):\n",
    "    spell = SpellChecker()\n",
    "    words = text.split()\n",
    "    corrected_words = [spell.correction(word) if spell.correction(word) is not None else word for word in words]\n",
    "    return ' '.join(corrected_words)\n",
    "\n",
    "# Apply spell correction to the first row only\n",
    "dataset['text'] = dataset['text'].apply(spell_correction)\n",
    "\n",
    "# Display the entire dataset\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "678d2f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
    "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
    "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're','s', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
    "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
    "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
    "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
    "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f9e3eb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25                                   I LOVE u guys best\n",
       "26    im meeting one besties tonight Cant wait GIRL ...\n",
       "27    Thanks Twitter add punish I got meet HIN show ...\n",
       "28    Being sick really cheap hurts much eat real fo...\n",
       "29                                      effect everyone\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwordlist)\n",
    "def cleaning_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "dataset['text'] = dataset['text'].apply(lambda text: cleaning_stopwords(text))\n",
    "dataset['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c2b42d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25                             [I, LOVE, u, guys, best]\n",
       "26    [im, meeting, one, besties, tonight, Cant, wai...\n",
       "27    [Thanks, Twitter, add, punish, I, got, meet, H...\n",
       "28    [Being, sick, really, cheap, hurts, much, eat,...\n",
       "29                                   [effect, everyone]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "dataset['text'] = dataset['text'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "dataset['text'] = dataset['text'].apply(tokenizer.tokenize)\n",
    "dataset['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "16be636f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25                             [I, LOVE, u, guys, best]\n",
       "26    [im, meeting, one, besties, tonight, Cant, wai...\n",
       "27    [Thanks, Twitter, add, punish, I, got, meet, H...\n",
       "28    [Being, sick, really, cheap, hurts, much, eat,...\n",
       "29                                   [effect, everyone]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data\n",
    "dataset['text']= dataset['text'].apply(lambda x: stemming_on_text(x))\n",
    "dataset['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "12de3e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25                             [I, LOVE, u, guys, best]\n",
       "26    [im, meeting, one, besties, tonight, Cant, wai...\n",
       "27    [Thanks, Twitter, add, punish, I, got, meet, H...\n",
       "28    [Being, sick, really, cheap, hurts, much, eat,...\n",
       "29                                   [effect, everyone]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = nltk.WordNetLemmatizer()\n",
    "def lemmatizer_on_text(data):\n",
    "    text = [lm.lemmatize(word) for word in data]\n",
    "    return data\n",
    "dataset['text'] = dataset['text'].apply(lambda x: lemmatizer_on_text(x))\n",
    "dataset['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19634abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose an option:\n",
      "1. Remove Punctuation and Known Emojis\n",
      "2. Convert Emoticons to Words\n",
      "3. Quit\n",
      "Enter the option number: 1\n",
      "Punctuation and known emojis removed from 'text' column.\n",
      "Output after removing punctuation and known emojis:\n",
      "['I', 'LOVE', 'u', 'guys', 'best']\n",
      "['im', 'meeting', 'one', 'besties', 'tonight', 'Cant', 'wait', 'GIRL', 'TALK']\n",
      "['Thanks', 'Twitter', 'add', 'punish', 'I', 'got', 'meet', 'HIN', 'show', 'area', 'sweetheart']\n",
      "['Being', 'sick', 'really', 'cheap', 'hurts', 'much', 'eat', 'real', 'food', 'Plus', 'friends', 'make', 'soup']\n",
      "['effect', 'everyone']\n",
      "Choose an option:\n",
      "1. Remove Punctuation and Known Emojis\n",
      "2. Convert Emoticons to Words\n",
      "3. Quit\n",
      "Enter the option number: 2\n",
      "You chose Option 2\n",
      "Choose an option:\n",
      "1. Remove Punctuation and Known Emojis\n",
      "2. Convert Emoticons to Words\n",
      "3. Quit\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Define a custom list of known emojis to remove\n",
    "custom_emojis = ['üòÄ', 'üòÉ', 'üòÑ', 'üòÅ', 'üòÜ', 'üòÖ', 'üòÇ', 'ü§£', 'üòä', 'üòá']  # Add more emojis as needed\n",
    "\n",
    "# Define the punctuation list\n",
    "punctuations_list = string.punctuation\n",
    "\n",
    "# Function to remove punctuation and known emojis from a string\n",
    "def remove_punctuations_and_known_emojis(text):\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    text_without_punctuations = text.translate(translator)\n",
    "    for emoji in custom_emojis:\n",
    "        text_without_punctuations = text_without_punctuations.replace(emoji, '')\n",
    "    return text_without_punctuations\n",
    "\n",
    "# Function to process a list of strings within each cell\n",
    "def process_text_list(text_list, process_function):\n",
    "    return [process_function(text) for text in text_list]\n",
    "\n",
    "# Display the menu and get the user's choice\n",
    "while True:\n",
    "    print(\"Choose an option:\")\n",
    "    print(\"1. Remove Punctuation and Known Emojis\")\n",
    "    print(\"2. Convert Emoticons to Words\")\n",
    "    print(\"3. Quit\")\n",
    "    choice = input(\"Enter the option number: \")\n",
    "\n",
    "    if choice == '1':\n",
    "        dataset['text'] = [process_text_list(text, remove_punctuations_and_known_emojis) for text in dataset['text']]\n",
    "        print(\"Punctuation and known emojis removed from 'text' column.\")\n",
    "        # Print the first few rows of the 'text' column after processing\n",
    "        print(\"Output after removing punctuation and known emojis:\")\n",
    "        for text in dataset['text'][:5]:  # Print the first 5 rows as an example\n",
    "            print(text)\n",
    "    elif choice == '2':\n",
    "        # Add your code for Option 2 (Emoticon to Word conversion) here\n",
    "        print(\"You chose Option 2\")\n",
    "    elif choice == '3':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Invalid choice. Please select a valid option (1, 2, or 3).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c270e17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2524f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ff4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
